{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41bae6b-8702-4d6f-9c8c-2e506dfc6886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /mnt/d/forCoding_data/Tianchi_Ecommerce6/plan_1\n",
      "code dir: /mnt/d/forCoding_code/Tianchi_Ecommerce6/plan_1\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/d/forCoding_code/_init_tools/x__params.py\", \"r\") as f:\n",
    "    txt = f.read()\n",
    "exec(txt)\n",
    "\n",
    "with open(\"/mnt/d/forCoding_code/_init_tools/report_macro_0516.py\", \"r\") as f:\n",
    "    txt = f.read()\n",
    "exec(txt)\n",
    "\n",
    "with open(\"/mnt/d/forCoding_code/_init_tools/x__tool_here1.py\", \"r\") as f:\n",
    "    exec(f.read())\n",
    "with open(\"/mnt/d/forCoding_code/_init_tools/x__tool_here2.py\", \"r\") as f:\n",
    "    exec(f.read())\n",
    "\n",
    "wasted_dir = \"./wasted\"\n",
    "if not os.path.exists(wasted_dir):\n",
    "    os.makedirs(wasted_dir)\n",
    "\n",
    "pd.set_option('display.max_rows',200)\n",
    "pd.set_option('display.max_columns',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f0c8c04-6166-413f-8484-de0bdcc24693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Using device: cuda\n",
      "Training Extraction Model...\n",
      "Some weights of ExtractionModel were not initialized from the model checkpoint at /mnt/d/ModelScopeModels/google-bert/bert-base-chinese/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.66it/s]\n",
      "Loss: 0.2684578331611534\n",
      "Epoch 2: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.66it/s]\n",
      "Loss: 0.12919908852344103\n",
      "Epoch 3: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.64it/s]\n",
      "Loss: 0.0920891799585949\n",
      "Epoch 4: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.64it/s]\n",
      "Loss: 0.06917608515497777\n",
      "Epoch 5: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.63it/s]\n",
      "Loss: 0.0481434217585011\n",
      "Epoch 6: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.63it/s]\n",
      "Loss: 0.037732288259828446\n",
      "Epoch 7: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.02584355969862588\n",
      "Epoch 8: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.021094163165699766\n",
      "Epoch 9: 100%|████████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.015847240844372622\n",
      "Epoch 10: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.013485606947088485\n",
      "Epoch 11: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.010633760263006858\n",
      "Epoch 12: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.009686590895911973\n",
      "Epoch 13: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.00873988871502985\n",
      "Epoch 14: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.63it/s]\n",
      "Loss: 0.005493982599735246\n",
      "Epoch 15: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.00601877781345237\n",
      "Epoch 16: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.005662874687932164\n",
      "Epoch 17: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.0040896075664896125\n",
      "Epoch 18: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.00424602967717928\n",
      "Epoch 19: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.0039078770056617616\n",
      "Epoch 20: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.0031141744530932647\n",
      "Epoch 21: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.0026834231453309746\n",
      "Epoch 22: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.002492873238837335\n",
      "Epoch 23: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.0027091894568218437\n",
      "Epoch 24: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.62it/s]\n",
      "Loss: 0.002251842954498024\n",
      "Epoch 25: 100%|███████████████████████████████| 202/202 [00:55<00:00,  3.61it/s]\n",
      "Loss: 0.001860971294254431\n",
      "Training Classification Model...\n",
      "Some weights of ClassificationModel were not initialized from the model checkpoint at /mnt/d/ModelScopeModels/google-bert/bert-base-chinese/ and are newly initialized: ['cat_classifier.bias', 'cat_classifier.weight', 'pol_classifier.bias', 'pol_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 1.0385697381610122\n",
      "Epoch 2: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.3615077685193795\n",
      "Epoch 3: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.25226792520719354\n",
      "Epoch 4: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.20026525047047358\n",
      "Epoch 5: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.16278091708503842\n",
      "Epoch 6: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.12200383955304515\n",
      "Epoch 7: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.11783485686430005\n",
      "Epoch 8: 100%|████████████████████████████████| 713/713 [03:12<00:00,  3.70it/s]\n",
      "Loss: 0.09187467559404033\n",
      "Epoch 9: 100%|████████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.0798832899864716\n",
      "Epoch 10: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.06519984804893234\n",
      "Epoch 11: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.046361265416507876\n",
      "Epoch 12: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.04527585667399311\n",
      "Epoch 13: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.028767052910037255\n",
      "Epoch 14: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.026431051716580726\n",
      "Epoch 15: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.029481790948079227\n",
      "Epoch 16: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.017445089380491295\n",
      "Epoch 17: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.014073198017086912\n",
      "Epoch 18: 100%|███████████████████████████████| 713/713 [04:30<00:00,  2.64it/s]\n",
      "Loss: 0.011558711097567887\n",
      "Epoch 19: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.68it/s]\n",
      "Loss: 0.01009636976079216\n",
      "Epoch 20: 100%|███████████████████████████████| 713/713 [03:14<00:00,  3.67it/s]\n",
      "Loss: 0.00792082230605219\n",
      "Epoch 21: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.69it/s]\n",
      "Loss: 0.0049327415894428964\n",
      "Epoch 22: 100%|███████████████████████████████| 713/713 [03:13<00:00,  3.68it/s]\n",
      "Loss: 0.005581808268433165\n",
      "Epoch 23: 100%|███████████████████████████████| 713/713 [03:43<00:00,  3.20it/s]\n",
      "Loss: 0.005248400767394707\n",
      "Epoch 24: 100%|███████████████████████████████| 713/713 [05:38<00:00,  2.11it/s]\n",
      "Loss: 0.0032312544417857528\n",
      "Epoch 25: 100%|███████████████████████████████| 713/713 [05:38<00:00,  2.11it/s]\n",
      "Loss: 0.0028983090008947955\n",
      "\n",
      "\n",
      "\n",
      "Starting Prediction...\n",
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Running Extraction...\n",
      "Some weights of ExtractionModel were not initialized from the model checkpoint at /mnt/d/ModelScopeModels/google-bert/bert-base-chinese/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████| 140/140 [00:21<00:00,  6.47it/s]\n",
      "Running Classification...\n",
      "Some weights of ClassificationModel were not initialized from the model checkpoint at /mnt/d/ModelScopeModels/google-bert/bert-base-chinese/ and are newly initialized: ['cat_classifier.bias', 'cat_classifier.weight', 'pol_classifier.bias', 'pol_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████| 498/498 [01:15<00:00,  6.59it/s]\n",
      "Saved results to /mnt/d/forCoding_data/Tianchi_Ecommerce6/plan_1/preprocessedData/Result.csv\n",
      "\n",
      "\n",
      "\n",
      "Starting Evaluation...\n",
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Using device: cuda\n",
      "Loading Train Data for Evaluation...\n",
      "Running Extraction on Train Set...\n",
      "Some weights of ExtractionModel were not initialized from the model checkpoint at /mnt/d/ModelScopeModels/google-bert/bert-base-chinese/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Extraction: 100%|█████████████████████████████| 202/202 [00:32<00:00,  6.20it/s]\n",
      "Running Classification on Candidate Pairs...\n",
      "Some weights of ClassificationModel were not initialized from the model checkpoint at /mnt/d/ModelScopeModels/google-bert/bert-base-chinese/ and are newly initialized: ['cat_classifier.bias', 'cat_classifier.weight', 'pol_classifier.bias', 'pol_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classification: 100%|█████████████████████████| 687/687 [01:44<00:00,  6.60it/s]\n",
      "Computing F1 Score...\n",
      "------------------------------\n",
      "Correct (S): 6451\n",
      "Predicted (P): 6458\n",
      "Ground Truth (G): 6632\n",
      "------------------------------\n",
      "Precision: 0.9989\n",
      "Recall:    0.9727\n",
      "F1 Score:  0.9856\n",
      "------------------------------\n",
      "Error analysis saved to error_analysis.txt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!sh run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75b6ac1e-9545-4082-87d8-679c406bc0a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '【' (U+3010) (3959778399.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m【TODO】增大轮数，难样本挖掘，数据增强，使用新的数据（可能借助大模型），换模型。\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '【' (U+3010)\n"
     ]
    }
   ],
   "source": [
    "【TODO】增大轮数，难样本挖掘，数据增强，使用新的数据（可能借助大模型），换模型。\n",
    "【TODO】polarity中性的样本，换一种处理方式？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b1998-8a81-43b2-948c-e7cf77ee3364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6abed-b794-421e-a364-d8b416b328d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf5334-2948-48ee-bca4-a972816f2e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b8160-515f-4826-b989-5440ed875c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
